# Variational-Autoencoder-Exploration-With-MINSIT
Implementing Variational Autoencoder and explored the importance of each part of its loss function. 


1. [General](#General)
    - [Background](#background)
    - [Program Structure](https://github.com/elaysason/Variational-Autoencoder-Exploration-With-MINST/blob/main/README.md#program-structure)
    - [Running Instructions](https://github.com/elaysason/Variational-Autoencoder-Exploration-With-MINST/blob/main/README.md#running-instructions)
2. [Installation](#installation)
3. [Footnote](#footnote)

## General

### Background
This notbook is  another look into deep learning, this time into Variational-Autoencoders(or VAE in short).VAE is an autoencoder whose encodings distribution is regularised during the training in order to ensure that its latent space has good properties allowing us to generate new images. The VAE in our case while using the MINST data set will generate new number images using the latent variblies learned in the training fase.

### Program Structure
